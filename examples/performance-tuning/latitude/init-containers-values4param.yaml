# hedera node configuration
hedera:
  initContainers:
    - name: init-hedera-node
      image: busybox:stable-musl
      command: ["sh", "-c", "cp -r /etc /data-saved"]
      volumeMounts:
        - name: hgcapp-data-saved
          mountPath: /data-saved
  nodes:
    - name: node1
      nodeId: 0
      accountId: 0.0.3
      root:
        resources:
          requests:
            cpu: %HALFOFCORES%
            memory: %RAMMINUS16%Gi
          limits:
            cpu: %CORES%
            memory: %RAMMINUS1%Gi
    - name: node2
      nodeId: 1
      accountId: 0.0.4
      root:
        resources:
          requests:
            cpu: %HALFOFCORES%
            memory: %RAMMINUS16%Gi
          limits:
            cpu: %CORES%
            memory: %RAMMINUS1%Gi
    - name: node3
      nodeId: 2
      accountId: 0.0.5
      root:
        resources:
          requests:
            cpu: %HALFOFCORES%
            memory: %RAMMINUS16%Gi
          limits:
            cpu: %CORES%
            memory: %RAMMINUS1%Gi
    - name: node4
      nodeId: 3
      accountId: 0.0.6
      root:
        resources:
          requests:
            cpu: %HALFOFCORES%
            memory: %RAMMINUS16%Gi
          limits:
            cpu: %CORES%
            memory: %RAMMINUS1%Gi
defaults:
  haproxy:
    serviceType: NodePort
  envoyProxy:
    loadBalancerEnabled: true
  sidecars:
    recordStreamUploader:
      resources:
        requests:
          cpu: 100m
          memory: 100Mi
        limits:
          cpu: 150m
          memory: 200Mi
    eventStreamUploader:
      resources:
        requests:
          cpu: 100m
          memory: 100Mi
        limits:
          cpu: 150m
          memory: 200Mi
    recordStreamSidecarUploader:
      resources:
        requests:
          cpu: 100m
          memory: 100Mi
        limits:
          cpu: 150m
          memory: 200Mi
    blockstreamUploader:
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
        limits:
          cpu: 150m
          memory: 400Mi
  root:
    resources:
      requests:
        cpu: %HALFOFCORES%
        memory: %RAMMINUS16%Gi
      limits:
        cpu: %CORES%
        memory: %RAMMINUS1%Gi
    extraEnv:
      - name: JAVA_OPTS
        value: "-XX:+UnlockExperimentalVMOptions -XX:+UseZGC -XX:ZAllocationSpikeTolerance=2 -XX:ConcGCThreads=%HALFOFCORES% -XX:MaxDirectMemorySize=4g -XX:MetaspaceSize=100M -XX:+ZGenerational -Xlog:gc*:gc.log --add-opens java.base/jdk.internal.misc=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED -Dio.netty.tryReflectionSetAccessible=true"
      - name: JAVA_HEAP_MIN
        value: "%RAMMINUS16%g"
      - name: JAVA_HEAP_MAX
        value: "%RAMMINUS6%g"
      - name: MALLOC_ARENA_MAX
        value: "4"

minio-server:
  tenant:
    pools:
      - servers: 1
        name: pool-1
        volumesPerServer: 1
        size: 500Gi
        storageClassName: local-path
        nodeSelector:
          solo.hashgraph.io/role: "auxiliary-services"
          solo.hashgraph.io/owner: "%NETWORK_OWNER%"
          solo.hashgraph.io/network-id: "%NETWORK_ID%"
        tolerations:
          - key: "solo.hashgraph.io/role"
            operator: "Equal"
            value: "auxiliary-services"
            effect: "NoSchedule"
          - key: "solo.hashgraph.io/owner"
            operator: "Equal"
            value: "%NETWORK_OWNER%"
            effect: "NoSchedule"
          - key: "solo.hashgraph.io/network-id"
            operator: "Equal"
            value: "%NETWORK_ID%"
            effect: "NoSchedule"
        resources:
          requests:
            cpu: 0
            memory: 0
          limits:
            cpu: 0
            memory: 0
deployment:
  podAnnotations: {}
  podLabels: {}
  nodeSelector:
    solo.hashgraph.io/role: "consensus-node"
    solo.hashgraph.io/owner: "%NETWORK_OWNER%"
    solo.hashgraph.io/network-id: "%NETWORK_ID%"
  tolerations:
    - key: "solo.hashgraph.io/role"
      operator: "Equal"
      value: "consensus-node"
      effect: "NoSchedule"
    - key: "solo.hashgraph.io/owner"
      operator: "Equal"
      value: "%NETWORK_OWNER%"
      effect: "NoSchedule"
    - key: "solo.hashgraph.io/network-id"
      operator: "Equal"
      value: "%NETWORK_ID%"
      effect: "NoSchedule"
haproxyDeployment:
  nodeSelector:
    solo.hashgraph.io/role: "auxiliary-services"
    solo.hashgraph.io/owner: "%NETWORK_OWNER%"
    solo.hashgraph.io/network-id: "%NETWORK_ID%"
  tolerations:
    - key: "solo.hashgraph.io/role"
      operator: "Equal"
      value: "auxiliary-services"
      effect: "NoSchedule"
    - key: "solo.hashgraph.io/owner"
      operator: "Equal"
      value: "%NETWORK_OWNER%"
      effect: "NoSchedule"
    - key: "solo.hashgraph.io/network-id"
      operator: "Equal"
      value: "%NETWORK_ID%"
      effect: "NoSchedule"
envoyDeployment:
  nodeSelector:
    solo.hashgraph.io/role: "auxiliary-services"
    solo.hashgraph.io/owner: "%NETWORK_OWNER%"
    solo.hashgraph.io/network-id: "%NETWORK_ID%"
  tolerations:
    - key: "solo.hashgraph.io/role"
      operator: "Equal"
      value: "auxiliary-services"
      effect: "NoSchedule"
    - key: "solo.hashgraph.io/owner"
      operator: "Equal"
      value: "%NETWORK_OWNER%"
      effect: "NoSchedule"
    - key: "solo.hashgraph.io/network-id"
      operator: "Equal"
      value: "%NETWORK_ID%"
      effect: "NoSchedule"
