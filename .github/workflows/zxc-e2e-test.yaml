##
# Copyright (C) 2023-2024 Hedera Hashgraph, LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
##

name: "ZXC: E2E Test"
# The purpose of this reusable workflow is to run the e2e tests on every PR and commit.
# This reusable component is called by the following workflows:
# - .github/workflows/flow-pull-request-checks.yaml
# - .github/workflows/flow-build-application.yaml

on:
  workflow_dispatch:
    inputs:
      node-version:
        description: "NodeJS Version:"
        type: string
        required: false
        default: "22"
      consensus-node-version:
        description: "Consensus Node Version:"
        type: string
        required: false
        default: ""
      custom-job-label:
        description: "Custom Job Label:"
        type: string
        required: false
        default: "E2E Test"
      test-script:
        description: "NPM Test Run Script:"
        type: string
        required: false
        default: "test-e2e-standard"
      coverage-subdirectory:
        description: "Coverage Report Subdirectory:"
        type: string
        required: false
        default: "e2e"
      coverage-report-name:
        description: "Coverage Report Name:"
        type: string
        required: false
        default: "E2E Tests Coverage Report"
      local-java-build:
        description: "Build Local Java Code:"
        type: boolean
        required: false
        default: false
      cluster-name:
        description: "Cluster Name:"
        type: string
        required: false
        default: "solo-e2e"
      install-dependencies:
        description: "Install Solo Dependencies:"
        type: boolean
        required: false
        default: true
      runner:
        description: "Runner Label:"
        type: string
        required: false
        default: "hiero-solo-linux-large"
  workflow_call:
    inputs:
      node-version:
        description: "NodeJS Version:"
        type: string
        required: false
        default: "22"
      consensus-node-version:
        description: "Consensus Node Version:"
        type: string
        required: false
        default: ""
      custom-job-label:
        description: "Custom Job Label:"
        type: string
        required: false
        default: "E2E Test"
      test-script:
        description: "NPM Test Run Script:"
        type: string
        required: false
        default: "test-e2e-standard"
      coverage-subdirectory:
        description: "Coverage Report Subdirectory:"
        type: string
        required: false
        default: "e2e"
      coverage-report-name:
        description: "Coverage Report Name:"
        type: string
        required: false
        default: "E2E Tests Coverage Report"
      local-java-build:
        description: "Build Local Java Code:"
        type: boolean
        required: false
        default: false
      cluster-name:
        description: "Cluster Name:"
        type: string
        required: false
        default: "solo-e2e"
      install-dependencies:
        description: "Install Solo Dependencies:"
        type: boolean
        required: false
        default: true
      runner:
        description: "Runner Label:"
        type: string
        required: false
        default: "hiero-solo-linux-large"

defaults:
  run:
    shell: bash

permissions:
  id-token: write
  contents: read
  actions: read
  pull-requests: write
  checks: write
  statuses: write

env:
  #CG_EXEC: export R_UID=$(id -u); CGROUP_LOGLEVEL=DEBUG cgexec -g cpu,memory:user.slice/user-${R_UID}.slice/user@${R_UID}.service/e2e-${{ github.run_id }} --sticky ionice -c 2 -n 2 nice -n 19
  CG_EXEC: "ionice -c 2 -n 2 nice -n 19"
  SOLO_CLUSTER_DUALITY: ${{ (inputs.test-script == 'test-e2e-dual-cluster-full' || inputs.test-script == 'test-e2e-external-database') && 2 || 1 }}

jobs:
  e2e-test:
    name: ${{ inputs.custom-job-label || 'E2E Test' }}
    runs-on: ${{ inputs.runner || 'hiero-solo-linux-large' }}
    steps:
      - name: Harden Runner
        uses: step-security/harden-runner@df199fb7be9f65074067a9eb93f12bb4c5547cf2 # v2.13.3
        with:
          egress-policy: audit

      - name: Checkout Code
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1

      #      - name: Setup Control Groups
      #        run: |
      #          echo "::group::Get System Configuration"
      #            USR_ID="$(id -un)"
      #            GRP_ID="$(id -gn)"
      #            E2E_MEM_LIMIT="30064771072"
      #            AGENT_MEM_LIMIT="2147483648"
      #            USER_SLICE="user.slice/user-$(id -u).slice"
      #            USER_SERVICE="${USER_SLICE}/user@$(id -u).service"
      #            E2E_GROUP_NAME="${USER_SERVICE}/e2e-${{ github.run_id }}"
      #            AGENT_GROUP_NAME="${USER_SERVICE}/agent-${{ github.run_id }}"
      #          echo "::endgroup::"
      #
      #          echo "::group::Install Control Group Tools"
      #            if ! command -v cgcreate >/dev/null 2>&1; then
      #              sudo apt-get update
      #              sudo apt-get install -y cgroup-tools
      #            fi
      #          echo "::endgroup::"
      #
      #          echo "::group::Create Control Groups"
      #            sudo cgcreate -g cpu,memory:${USER_SLICE} -a ${USR_ID}:${GRP_ID} -t ${USR_ID}:${GRP_ID}
      #            sudo cgcreate -g cpu,memory:${USER_SERVICE} -a ${USR_ID}:${GRP_ID} -t ${USR_ID}:${GRP_ID}
      #            sudo cgcreate -g cpu,memory:${E2E_GROUP_NAME} -a ${USR_ID}:${GRP_ID} -t ${USR_ID}:${GRP_ID}
      #            sudo cgcreate -g cpu,memory:${AGENT_GROUP_NAME} -a ${USR_ID}:${GRP_ID} -t ${USR_ID}:${GRP_ID}
      #          echo "::endgroup::"
      #
      #          echo "::group::Set Control Group Limits"
      #            cgset -r cpu.weight=768 ${E2E_GROUP_NAME}
      #            cgset -r cpu.weight=500 ${AGENT_GROUP_NAME}
      #            cgset -r memory.max=${E2E_MEM_LIMIT} ${E2E_GROUP_NAME}
      #            cgset -r memory.max=${AGENT_MEM_LIMIT} ${AGENT_GROUP_NAME}
      #            cgset -r memory.swap.max=${E2E_MEM_LIMIT} ${E2E_GROUP_NAME}
      #            cgset -r memory.swap.max=${AGENT_MEM_LIMIT} ${AGENT_GROUP_NAME}
      #          echo "::endgroup::"
      #
      #          echo "::group::Move Runner Processes to Control Groups"
      #            sudo cgclassify --sticky -g cpu,memory:${AGENT_GROUP_NAME} $(pgrep 'Runner.Listener' | tr '\n' ' ')
      #            sudo cgclassify -g cpu,memory:${AGENT_GROUP_NAME} $(pgrep 'Runner.Worker' | tr '\n' ' ')
      #          echo "::endgroup::"

      - name: Setup Posix Dependencies
        id: set-posix-dependencies
        run: |
          # Install jq (a lightweight and flexible command-line JSON processor)
          sudo apt-get update && sudo apt-get install -y jq

      - name: Setup Node
        uses: actions/setup-node@395ad3262231945c25e8478fd5baf05154b1d79f # v6.1.0
        with:
          node-version: ${{ inputs.node-version }}

      - name: Install wget
        run: |
          if ! command -v wget >/dev/null 2>&1; then
            sudo apt-get update
            sudo apt-get install -y wget
          fi

      - name: Install Kubectl
        if: ${{ inputs.install-dependencies == true }}
        uses: step-security/setup-kubectl@fa3574e17195eaed56b1e9d9095c58d0aee24f03 # pinned to v4.0.1
        with:
          version: 'v1.27.3'
        id: install

      - name: Setup Kind
        if: ${{ inputs.install-dependencies == true }}
        uses: helm/kind-action@92086f6be054225fa813e0a4b13787fc9088faab # v1.13.0
        with:
          install_only: true
          node_image: kindest/node:v1.31.4@sha256:2cb39f7295fe7eafee0842b1052a599a4fb0f8bcf3f83d96c7f4864c357c6c30
          version: v0.26.0
          kubectl_version: v1.31.4
          verbosity: 3
          wait: 120s

      - name: Setup Helm
        if: ${{ inputs.install-dependencies == true }}
        uses: azure/setup-helm@1a275c3b69536ee54be43f2070a358922e12c8d4 # v4.3.1
        with:
          version: "v3.17.1" # helm version

      - name: Install Dependencies
        id: npm-deps
        uses: step-security/retry@e1d59ce1f574b32f0915e3a8df055cfe9f99be5d # v3.0.4
        with:
          max_attempts: 10
          timeout_minutes: 10
          command: |
            npm ci

      - name: Install Task
        uses: arduino/setup-task@b91d5d2c96a56797b48ac1e0e89220bf64044611 # v2.0.0
        with:
          version: 3.39.2
          repo-token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Go
        uses: actions/setup-go@4dc6199c7b1a012772edbd06daecab0f50c9053c # v6.1.0
        with:
          go-version: '1.22.3'

      - name: Install grpcurl
        run: |
          go install github.com/fullstorydev/grpcurl/cmd/grpcurl@latest

      - name: Compile Project
        run: task build

      - name: Pull Kind Docker Image
        if: ${{ inputs.custom-job-label != 'One Shot Single - using Podman' }}
        run: docker image pull kindest/node:v1.31.4@sha256:2cb39f7295fe7eafee0842b1052a599a4fb0f8bcf3f83d96c7f4864c357c6c30

      - name: Install Podman
        if: ${{ inputs.test-script == 'test-e2e-node-local-ptt' }}
        run: |
          # Detect distro and install Podman + essential dependencies for rootful mode
          if [ -f /etc/debian_version ]; then
            sudo apt-get update
            sudo apt-get install -y podman iptables
          elif [ -f /etc/redhat-release ]; then
            # Keep your RedHat logic if needed
            true
          else
            echo "Unsupported distro"
            exit 1
          fi
          
          podman --version
          
          # Verify Podman works in rootful mode
          echo "Verifying Podman in rootful mode..."
          sudo podman info
          sudo podman ps
          echo "Podman is ready"


      - name: Setup Java
        if: ${{ runner.os == 'linux' && inputs.local-java-build && !cancelled() && !failure() }}
        uses: actions/setup-java@dded0888837ed1f317902acf8a20df0ad188d165 # v5.0.0
        with:
          distribution: temurin
          java-version: 21.0.1

      - name: Setup Gradle
        if: ${{ runner.os == 'linux' && inputs.local-java-build && !cancelled() && !failure() }}
        uses: gradle/actions/setup-gradle@4d9f0ba0025fe599b4ebab900eb7f3a1d93ef4c2 # v5.0.0
        with:
          cache-read-only: false

      - name: Create Diagnostic Script
        env:
          WRITE_DIAG_SCRIPT: ${{ github.workspace }}/.github/workflows/script/write_diag_script.sh
        run: |
          sudo chmod +x "${WRITE_DIAG_SCRIPT}"
          ${WRITE_DIAG_SCRIPT}

      - name: Build Hedera code locally
        if: ${{ runner.os == 'linux' && inputs.local-java-build && !cancelled() && !failure() }}
        run: |
          if [ -z "${{ inputs.consensus-node-version }}" ]; then
              export CONSENSUS_NODE_VERSION=$(grep 'TEST_LOCAL_HEDERA_PLATFORM_VERSION' version-test.ts | sed -E "s/.*'([^']+)';/\1/")
          else
              export CONSENSUS_NODE_VERSION=${{ inputs.consensus-node-version }}
          fi
          cd ..
          git clone https://github.com/hiero-ledger/hiero-consensus-node.git --depth 1 --branch ${CONSENSUS_NODE_VERSION}
          cd hiero-consensus-node
          ls -ltr
          ${{ env.CG_EXEC }} ./gradlew assemble --stacktrace --info
          cd ../solo

      - name: Setup E2E Tests
        if: ${{ !cancelled() && inputs.test-script != 'test-e2e-node-local-ptt' && inputs.custom-job-label != 'One Shot Single - using Podman' }}
        uses: step-security/retry@e1d59ce1f574b32f0915e3a8df055cfe9f99be5d # v3.0.4
        with:
          max_attempts: 3
          timeout_minutes: 10
          command: |
            npm link
            echo "SOLO_TEST_CLUSTER=${{ inputs.cluster-name }}"
            SOLO_TEST_CLUSTER=${{ inputs.cluster-name }} ${{ env.CG_EXEC }} ./test/e2e/dual-cluster/setup-dual-e2e.sh

      - name: Setup Podman & Kind Cluster for E2E Tests
        if: ${{ !cancelled() && inputs.test-script == 'test-e2e-node-local-ptt' }}
        uses: step-security/retry@e1d59ce1f574b32f0915e3a8df055cfe9f99be5d # v3.0.4
        with:
          max_attempts: 3
          timeout_minutes: 15
          command: |
            npm link
            echo "SOLO_TEST_CLUSTER=${{ inputs.cluster-name }}"
            echo "GITHUB_RUN_ID=${{ github.run_id }}"
            SOLO_TEST_CLUSTER=${{ inputs.cluster-name }} GITHUB_RUN_ID=${{ github.run_id }} ${{ env.CG_EXEC }} ./test/e2e/podman-kind/setup-podman-kind-e2e.sh

      - name: Build Block code locally
        if: ${{ runner.os == 'linux' && (inputs.test-script == 'test-e2e-block-node') && !cancelled() && !failure() }}
        run: |
          export TEST_LOCAL_BLOCK_NODE_VERSION=$(grep 'TEST_LOCAL_BLOCK_NODE_VERSION' version-test.ts | sed -E "s/.*'([^']+)';/\1/")          
          cd ..
          git clone https://github.com/hiero-ledger/hiero-block-node.git --depth 1 --branch v${TEST_LOCAL_BLOCK_NODE_VERSION}
          cd hiero-block-node
          ./gradlew :block-node-app:createDockerImage
          kind get clusters

          kind load docker-image block-node-server:${TEST_LOCAL_BLOCK_NODE_VERSION} --name ${{ inputs.cluster-name }}-c1
          ${{ env.CG_EXEC }} ./gradlew :block-node-app:createDockerImage
          cd ../solo

      - name: Run E2E Tests
        run: |
          # Set KUBECONFIG to the unique config for Podman-based test only
          if [[ "${{ inputs.test-script }}" == "test-e2e-node-local-ptt" ]]; then
            UNIQUE_KUBECONFIG="${HOME}/.kube/solo-${{ github.run_id }}.yaml"
            if [[ -f "${UNIQUE_KUBECONFIG}" ]]; then
              export KUBECONFIG="${UNIQUE_KUBECONFIG}"
              echo "Using unique KUBECONFIG for Podman test: ${KUBECONFIG}"
            else
              echo "Warning: Expected unique KUBECONFIG not found: ${UNIQUE_KUBECONFIG}"
              exit 1
            fi
          else
            echo "Using default KUBECONFIG (Kind action setup)"
          fi
          
          if [[ -z "${{ inputs.consensus-node-version }}" ]]; then
              if [[ "${{ inputs.local-java-build }}" != "true" ]]; then
                  echo "No consensus node version provided, using default from version-test.ts"
              else
                  if [[ "${{ inputs.test-script }}" == "test-e2e-block-node" ]]; then
                    echo "Use default from version.ts for block node test"
                  else
                    export CONSENSUS_NODE_VERSION=$(grep 'TEST_LOCAL_HEDERA_PLATFORM_VERSION' version-test.ts | sed -E "s/.*'([^']+)';/\1/")
                  fi
              fi
          else
              export CONSENSUS_NODE_VERSION=${{ inputs.consensus-node-version }}
          fi
          echo SOLO_TEST_CLUSTER=${{ inputs.cluster-name }}-c1 > .env
          
          if [[ "${{ inputs.custom-job-label }}" != "One Shot Single - using Podman" ]]; then
            # Verify cluster connectivity before running tests
            echo "Verifying cluster connectivity..."
            kubectl cluster-info || {
              echo "Error: Cannot connect to cluster"
              echo "KUBECONFIG: ${KUBECONFIG:-default}"
              kubectl config get-contexts || true
              exit 1
            }
          else 
            echo "SOLO_ONE_SHOT_MINIMAL_SETUP=true" >> .env
            echo "FORCE_PODMAN=true" >> .env
          fi
          
          cat .env
          
          ${{ env.CG_EXEC }} task ${{ inputs.test-script }}

      - name: Log Metrics
        id: log-metrics
        run: |
          for logFile in ~/.solo/logs/*.json; do 
            if [[ -f "$logFile" ]]; then
              echo "::group::JSON Format"
              cat $logFile | jq
              echo "::endgroup::" 
              echo "json_log=$(cat $logFile)" >> $GITHUB_OUTPUT
              echo "::group::Spreadsheet Format"
              echo "logFile=$logFile"
              JSON_FILENAME=$logFile ./.github/workflows/script/metrics.sh
              echo "::endgroup::"
            else
              echo "json_log={}" >> $GITHUB_OUTPUT
            fi
          done
          echo "solo_log_dir=$(cd ~/.solo/logs && pwd)" >> $GITHUB_OUTPUT

      - name: Write Log Metrics Message File
        id: log-metrics-file
        if: ${{ !cancelled() && !failure() && steps.log-metrics.outputs.json_log != '{}' }}
        env:
          LOG_FILE: "${{ steps.log-metrics.outputs.solo_log_dir }}/log_file.md"
          JSON_INPUT: "${{ toJSON(fromJSON(steps.log-metrics.outputs.json_log)) }}"
        run: |
          echo "## Log Metrics - ${{ inputs.custom-job-label }}" >> $LOG_FILE
          echo "" >> $LOG_FILE
          echo "<details>" >> $LOG_FILE
          echo "<summary>" >> $LOG_FILE
          echo "JSON Log Metrics" >> $LOG_FILE
          echo "</summary>" >> $LOG_FILE
          echo '<pre><code class="JSON">' >> $LOG_FILE
          echo "$JSON_INPUT" >> $LOG_FILE
          echo "</code></pre>" >> $LOG_FILE
          echo "</details>" >> $LOG_FILE
          echo "log_file=$LOG_FILE" >> $GITHUB_OUTPUT

      - name: Comment PR with Log Metrics
        if: >-
          ${{ !cancelled() && !failure() && github.event_name == 'pull_request' && 
          steps.log-metrics.outputs.json_log != '{}' && github.event.pull_request.head.repo.fork == false }}
        uses: step-security/actions-comment-pull-request@7f6021194300cf361f7ba99a346c4daa6cab809b # v3.0.1
        with:
          mode: recreate
          file-path: ${{ steps.log-metrics-file.outputs.log_file }}
          comment-tag: log-metrics-${{ inputs.test-script }}

      - name: Upload E2E Logs to GitHub
        if: ${{ github.event_name != 'workflow_dispatch' && inputs.test-script != 'test-e2e-external-database' && !cancelled() }}
        uses: actions/upload-artifact@330a01c490aca151604b8cf639adc76d48f6c5d4 # v5.0.0
        with:
          name: solo-${{ inputs.test-script }}.log
          path: ~/.solo/logs/*
          overwrite: true
          if-no-files-found: error

      - name: Upload E2E Test Report
        uses: actions/upload-artifact@330a01c490aca151604b8cf639adc76d48f6c5d4 # v5.0.0
        if: ${{ github.event_name != 'workflow_dispatch' && inputs.test-script != 'test-e2e-external-database' && steps.npm-deps.conclusion == 'success' && !cancelled() }}
        with:
          name: e2e_test_report_${{ inputs.test-script }}
          path: "junit-${{ inputs.coverage-subdirectory }}.xml"
          overwrite: true
          if-no-files-found: error

      - name: Publish E2E Coverage Report
        uses: actions/upload-artifact@330a01c490aca151604b8cf639adc76d48f6c5d4 # v5.0.0
        if: ${{ github.event_name != 'workflow_dispatch' && inputs.test-script != 'test-e2e-external-database' && !cancelled() }}
        with:
          name: ${{ inputs.coverage-report-name }}
          path: 'coverage/${{ inputs.coverage-subdirectory }}'
